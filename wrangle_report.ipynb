{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weratedogs is a popular Twitter account that shares pictures and ratings of various dogs. I will discuss my data collection and wrangling efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "The first step was to download the `twitter-archive-enhanced.csv` manually and uploading it to the project workspace. Then I used the requests library to programatically download the `image_predictions.tsv` dataset provided by Udacity instructor. Finally I gathered additional data(`retweet_count` and `favorite_count`) from the `tweet-json.txt` provided by Udacity because I was unable to access the tweeter api. I saved these datasets as tsv and csv respectively in the project workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Assessing\n",
    "\n",
    "The second step was to assess the data so as to find errors and dirt to clean up. This involved both visual and programatic assessments. First, I read the datasets to pandas dataframes using the `read_csv()` method.\n",
    "\n",
    "#### Visual assessment\n",
    "I printed the datasets in the notebooks and looked through the output. An example of problems in the `image_predictions.tsv` dataset was the non_breed dog names e.g. `shopping_cart` in the p1 column, row 8. In the `twitter-archive-enhanced.csv`, an example of problems was in the `source` column, which had the whole URL instead of just the source of the tweet. Also, the `name doggo floofer\tpupper puppo` columns had `None` string instead of `NaN` which represents nothingness in python.\n",
    "\n",
    "#### Programatic assessment\n",
    "I used the `.info() .describe(), .value_counts()` methods to see the summary statistics of the dataframes and counts of various columns. The name column had some unrealistic dog names such as *a, an, the, just* among others. There were also outliers in some columns e.g. rating_numerator had a value of *1771*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "This is the final step in the data wragling phase. It involved removing duplicates, replacing values in some columns, dropping other columns, handling errors, joining columns representing one variable to one column and finally merging the three datasets. I removed duplicates using the `drop_duplicates()` method, replaced erroneous values using the `.replace()` method, dropped columns that were not to be used in analysis using `drop()` method, joined the `doggo, floofer, pupper, puppo` columns using the `melt()` method and finally joined the cleaned datasets using the `merge()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "After loading the cleaned dataset to a dataframe for easier analysis, I performed the following analysis:\n",
    "\n",
    "1. The distribution of dogs rating: I Visualised the value counts of the `rating numerator` using the bar graph.\n",
    "2. The breed that gets most retweets: grouped the dataframe by `p1` - dog breed column and summed up the `retweet count` column of the grouped data and sorted the values in ascending order.\n",
    "3. The most favorite breed: performed same analysis as with the number 2 above but used `favorite count` column inplace of the `retweet count`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
